####################################
#####The Box-Cox Transformation#####
####################################
library(car)
bc = boxCox(model) #Automatically plots a 95% confidence interval for the lambda
lambda = bc$x[which(bc$y == max(bc$y))] #Extracting the best lambda value.
dist.bc = (cars$dist^lambda - 1)/lambda #Applying the Box-Cox transformation.
model.bc = lm(dist.bc ~ cars$speed) #Creating a new regression based on the
##############################################
#####Manual example with the cars dataset#####
##############################################
help(cars)
cars #Investigating the cars dataset.
#Basic numerical EDA for cars dataset.
summary(cars) #Five number summaries.
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
#Basic graphical EDA for cars dataset.
hist(cars$speed, xlab = "Speed in MPH", main = "Histogram of Speed")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
#Manual calculation of simple linear regression coefficients.
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2)
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
#Adding the least squares regression line to the plot.
abline(beta0, beta1, lty = 2)
#Calculating the residual values.
residuals = cars$dist - (beta0 + beta1*cars$speed)
#Note the sum of the residuals is 0.
sum(residuals)
#Visualizing the residuals.
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
#################################################
#####Automatic example with the cars dataset#####
#################################################
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
summary(model) #All the summary information for the model in question. Reports:
#Notice that the F-statistic value for the overall regression is the same as the
#square of the t-statistic value for the speed coefficient:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
####################################################
#####Checking assumptions with the cars dataset#####
####################################################
#Linearity
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
#Constant Variance & Independent Errors
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
#Normality
qqnorm(model$residuals)
qqline(model$residuals)
#Using the built-in plot() function to visualize the residual plots.
plot(model) #Note the addition of the loess smoother and scale-location plot
#####Predicting New Observations#####
#####################################
model$fitted.values #Returns the fitted values.
newdata = data.frame(speed = c(15, 20, 25)) #Creating a new data frame to pass
predict(model, newdata, interval = "confidence") #Construct confidence intervals
predict(model, newdata, interval = "prediction") #Construct prediction invervals
#Constructing confidence and prediction bands for the scope of our data.
newdata = data.frame(speed = 4:25)
conf.band = predict(model, newdata, interval = "confidence")
pred.band = predict(model, newdata, interval = "prediction")
#Visualizing the confidence and prediction bands.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2) #Plotting the regression line.
lines(newdata$speed, conf.band[, 2], col = "blue") #Plotting the lower confidence band.
lines(newdata$speed, conf.band[, 3], col = "blue") #Plotting the upper confidence band.
lines(newdata$speed, pred.band[, 2], col = "red") #Plotting the lower prediction band.
lines(newdata$speed, pred.band[, 3], col = "red") #Plotting the upper prediction band.
legend("topleft", c("Regression Line", "Conf. Band", "Pred. Band"),
lty = c(2, 1, 1), col = c("black", "blue", "red"))
####################################
#####The Box-Cox Transformation#####
####################################
library(car)
####################################
#####The Box-Cox Transformation#####
####################################
library(car)
bc = boxCox(model) #Automatically plots a 95% confidence interval for the lambda
#value that maximizes the likelihhood of transforming to
#normality.
names(model)
#Constructing confidence and prediction bands for the scope of our data.
newdata = data.frame(speed = 4:25)
conf.band = predict(model, newdata, interval = "confidence")
pred.band = predict(model, newdata, interval = "prediction")
#Visualizing the confidence and prediction bands.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2) #Plotting the regression line.
lines(newdata$speed, conf.band[, 2], col = "blue") #Plotting the lower confidence band.
conf.band = predict(model, newdata, interval = "confidence")
pred.band = predict(model, newdata, interval = "prediction")
conf.band
#Constructing confidence and prediction bands for the scope of our data.
newdata = data.frame(speed = 4:25)
conf.band = predict(model, newdata, interval = "confidence")
pred.band = predict(model, newdata, interval = "prediction")
conf.band
#Visualizing the confidence and prediction bands.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2) #Plotting the regression line.
lines(newdata$speed, conf.band[, 2], col = "blue") #Plotting the lower confidence band.
lines(newdata$speed, conf.band[, 3], col = "blue") #Plotting the upper confidence band.
lines(newdata$speed, pred.band[, 2], col = "red") #Plotting the lower prediction band.
lines(newdata$speed, pred.band[, 3], col = "red") #Plotting the upper prediction band.
#transformed variable.
(2**0.4-1)/0.4
lambda = bc$x[which(bc$y == max(bc$y))] #Extracting the best lambda value.
dist.bc = (cars$dist^lambda - 1)/lambda #Applying the Box-Cox transformation.
model.bc = lm(dist.bc ~ cars$speed) #Creating a new regression based on the
summary(model.bc) #Assessing the output of the new model.
plot(model.bc) #Assessing the assumptions of the new model.
setwd("../../python/WebscrapingCars.com")
t10 = read.csv("t102.csv")
View(t10)
library(tidyverse)
cor(t10$mileage, t10$age)
t2 = t10 %>%
select(mileage, age)
chisq.test(t2)
1/(1-0.8077**2)
0.8**0.5
cor(t10$age, t10$age)
cor(t10$age, t10$age**2)
